{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"testca\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "steel_schema = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                           StructField(\"X_minimum\", IntegerType(), True),\n",
    "                           StructField(\"X_maximum\", IntegerType(), True),\n",
    "                           StructField(\"Y_minimum\", IntegerType(), True),\n",
    "                           StructField(\"Y_maximum\", IntegerType(), True),\n",
    "                           StructField(\"Pixels_areas\", IntegerType(), True),\n",
    "                           StructField(\"X_perimeter\", IntegerType(), True),\n",
    "                           StructField(\"Y_perimeter\", IntegerType(), True),\n",
    "                           StructField(\"Sum_of_luminosity\", IntegerType(), True),\n",
    "                           StructField(\"Minimum_luminosity\", IntegerType(), True),\n",
    "                           StructField(\"Maximum_luminosity\", IntegerType(), True),\n",
    "                           StructField(\"Length_conveyer\", IntegerType(), True),\n",
    "                           StructField(\"TypeSteel_A300\", IntegerType(), True),\n",
    "                           StructField(\"TypeSteel_A400\", IntegerType(), True),\n",
    "                           StructField(\"SteelPlate_thickness\", IntegerType(), True),\n",
    "                           StructField(\"Edges_index\", FloatType(), True),\n",
    "                           StructField(\"Empty_index\", FloatType(), True),\n",
    "                           StructField(\"Square_index\", FloatType(), True),\n",
    "                           StructField(\"OutsideX_index\", FloatType(), True),\n",
    "                           StructField(\"EdgesX_index\", FloatType(), True),\n",
    "                           StructField(\"EdgesY_index\", FloatType(), True),\n",
    "                           StructField(\"OutsideGlobal_index\", FloatType(), True),\n",
    "                           StructField(\"LogOfAreas\", FloatType(), True),\n",
    "                           StructField(\"LogX_index\", FloatType(), True),\n",
    "                           StructField(\"LogY_index\", FloatType(), True),\n",
    "                           StructField(\"Orientation_index\", FloatType(), True),\n",
    "                           StructField(\"Luminosity_index\", FloatType(), True),\n",
    "                           StructField(\"SigmoidOfAreas\", FloatType(), True),\n",
    "                           StructField(\"Pastry\", IntegerType(), True),\n",
    "                           StructField(\"Z_scratch\", IntegerType(), True),\n",
    "                           StructField(\"K_scratch\", IntegerType(), True),\n",
    "                           StructField(\"Stains\", IntegerType(), True),\n",
    "                           StructField(\"Dirtiness\", IntegerType(), True),\n",
    "                           StructField(\"Bumps\", IntegerType(), True),\n",
    "                           StructField(\"Other_faults\", IntegerType(), True),\n",
    "                           StructField(\"target_col\", StringType(), True),\n",
    "                           ])\n",
    "steelpred_schema = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                           StructField(\"X_minimum\", IntegerType(), True),\n",
    "                           StructField(\"X_maximum\", IntegerType(), True),\n",
    "                           StructField(\"Y_minimum\", IntegerType(), True),\n",
    "                           StructField(\"Y_maximum\", IntegerType(), True),\n",
    "                           StructField(\"Pixels_areas\", IntegerType(), True),\n",
    "                           StructField(\"X_perimeter\", IntegerType(), True),\n",
    "                           StructField(\"Y_perimeter\", IntegerType(), True),\n",
    "                           StructField(\"Sum_of_luminosity\", IntegerType(), True),\n",
    "                           StructField(\"Minimum_luminosity\", IntegerType(), True),\n",
    "                           StructField(\"Maximum_luminosity\", IntegerType(), True),\n",
    "                           StructField(\"Length_conveyer\", IntegerType(), True),\n",
    "                           StructField(\"TypeSteel_A300\", IntegerType(), True),\n",
    "                           StructField(\"TypeSteel_A400\", IntegerType(), True),\n",
    "                           StructField(\"SteelPlate_thickness\", IntegerType(), True),\n",
    "                           StructField(\"Edges_index\", FloatType(), True),\n",
    "                           StructField(\"Empty_index\", FloatType(), True),\n",
    "                           StructField(\"Square_index\", FloatType(), True),\n",
    "                           StructField(\"OutsideX_index\", FloatType(), True),\n",
    "                           StructField(\"EdgesX_index\", FloatType(), True),\n",
    "                           StructField(\"EdgesY_index\", FloatType(), True),\n",
    "                           StructField(\"OutsideGlobal_index\", FloatType(), True),\n",
    "                           StructField(\"LogOfAreas\", FloatType(), True),\n",
    "                           StructField(\"LogX_index\", FloatType(), True),\n",
    "                           StructField(\"LogY_index\", FloatType(), True),\n",
    "                           StructField(\"Orientation_index\", FloatType(), True),\n",
    "                           StructField(\"Luminosity_index\", FloatType(), True),\n",
    "                           StructField(\"SigmoidOfAreas\", FloatType(), True),])\n",
    "\n",
    "#import dataset\n",
    "steeltrain_path = \"dataset/train_clean.csv\"\n",
    "steelpred_path = \"dataset/test.csv\"\n",
    "steel_train = spark.read.csv(steeltrain_path, header=True, schema=steel_schema)\n",
    "steel_pred = spark.read.csv(steelpred_path, header=True, schema=steelpred_schema)\n",
    "\n",
    "steel_train.cache\n",
    "steel_pred.cache\n",
    "\n",
    "#extract col names\n",
    "target_cols = steel_train.columns[-8:-1]\n",
    "feature_cols = steel_train.columns[1:-8]\n",
    "print(feature_cols,\"\\n\", target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "##cross validator\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "## MODEL CREATION\n",
    "#define scaler & assembler\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "#create pipelines for each target class\n",
    "pipelines = []\n",
    "for label_col in target_cols:\n",
    "    mlp = MultilayerPerceptronClassifier(featuresCol=\"scaled_features\", labelCol=label_col, layers=[len(feature_cols), 13, 6, 2])\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=label_col, metricName=\"f1\") \n",
    "    param_grid = ParamGridBuilder().addGrid(mlp.maxIter, [50, 100, 200]).addGrid(mlp.stepSize, [0.03, 0.1]).build()\n",
    "    cv = CrossValidator(estimator=mlp, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "    mlp_pipeline = Pipeline(stages=[assembler, scaler, cv])\n",
    "    pipelines.append(mlp_pipeline)\n",
    "\n",
    "#fit model\n",
    "models = []\n",
    "for pipeline in pipelines:\n",
    "    model = pipeline.fit(steel_train)\n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "##EXTRACTING & CONCATENATING PROBABILITIES FOR SUBMISSION\n",
    "combined_probs = steel_pred.select('id')\n",
    "#iterate through each model and extract predicted probabilities\n",
    "for i, model in enumerate(models):\n",
    "    prediction = model.transform(steel_pred) ##redudant FIX\n",
    "    \n",
    "    #rename probability columns\n",
    "    prob_col_name = f\"probability_{target_cols[i]}\" \n",
    "    prediction = prediction.withColumnRenamed(\"probability\", prob_col_name)\n",
    "\n",
    "    #join each prediction + new col names to combined_probability df\n",
    "    combined_probs = combined_probs.join(prediction.select('id', prob_col_name), on='id', how='inner')\n",
    "\n",
    "#extract column vectors\n",
    "comb_cols = combined_probs.columns[1:]\n",
    "combined_df1 = combined_probs.select(\"id\")\n",
    "\n",
    "#loop to convert dense vector into array\n",
    "for i in comb_cols:\n",
    "    array_col = vector_to_array(col(i), \"float32\").alias(i + \"_vec\")\n",
    "    combined_df1 = combined_df1.join(\n",
    "        combined_probs.select(\"id\", array_col),\n",
    "        on=\"id\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "#define function to return element index 1 = true probability from arrays\n",
    "def get_true_prob(array):\n",
    "    if array is not None and len(array) > 1:\n",
    "        return array[1]\n",
    "    else:\n",
    "        return None\n",
    "get_udf = udf(get_true_prob)\n",
    "\n",
    "#array column names of probabilities\n",
    "new_cols = combined_df1.columns[1:]\n",
    "\n",
    "#loop through array column names and target col names to append columns to new df\n",
    "for col_vec, i in zip(new_cols, target_cols):\n",
    "    combined_df1 = combined_df1.withColumn(i, get_udf(col(col_vec)))\n",
    "\n",
    "#select relevant columns for submission in final new df\n",
    "final_cols = target_cols.copy()\n",
    "final_cols.append(\"id\")\n",
    "final = combined_df1.select(final_cols)\n",
    "\n",
    "#check all is well\n",
    "final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#write to csv file\n",
    "final.write.option(\"header\",True).csv(\"dataset/final_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
